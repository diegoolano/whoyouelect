source ~/virtualenvs/diegobs4/bin/activate

#to kill hanging phantomjs
#http://stackoverflow.com/questions/6381229/how-to-kill-all-processes-matching-a-name
#pkill -f phantomjs

#if mongo is not running, run "mongod"  to start it


**** 3 step procedure to generate json file needed for front end display for a new search person

1.  python do_websearch_for.py "Kyle Janek"    #this calls the website's located in folders in data/  (excluding jsons and pickles) and saves the articles and meta data for the search locally. 
2.  python add_json_files_for.py "Kyle Janek"  #this takes the saved json files from the websearch and then puts them into mongodb
3.  python get_articles_for_person_then_find_and_save_relations.py "Kyle Janek"  #this step grabs the articles for Kyle Janek, and does name entity recognition on each and constructs the network.

    This will save 3 json files into data/jsons/Name*.   (smallnet, urls, textsnippets)

Then to view the small network in whoyouelect.com, 
   1)  place a copy of the three json files produced from step 3 into whoyouelect.com/data/
   2)  in explorer.html, add the person's info to variables "search_terms" and "center_node_attrs" and save the file.  ( THIS PART WILL EVENTUALLY BE MOVED TO MONGO easily )
   3)  Now go to whoyouelect.com/explorer.html?show=23&minor=1&s=Kyle%20Janek (substitute Kyle Janek for the 


If you want the larger network to be constructed as well, for step 3 above add "include_larger"
   1.  python get_articles_for_person_then_find_and_save_relations.py "Kyle Janek" include_larger

   OR if you already ran step three, you can just run:
  1. python generate_single_network.py "Kyle Janek" include_larger



********* 1 step procedure to generate small and medium json files for a person and to save debug output to a file
python do_websearch_for.py "Kyle Janek" do_full > kyle_janek-debug-output.txt 




To view larger network,
TODO

To add new source XYZ so that it is included in search results and front end results,
1) add XYZ line to do_websearch 
2) add folder XYZ to data/  and copy getlinks and getarcticles scripts from other sources and place in XYZ folder.  
   you may need to copy phantomscrape.py if getlinks doesn't work ( if content is generated by javascript )
3) Edit the two scripts   getlinks (or phantomscrape )  and getarticles so that they contain the url to the search page of the website along with a few DOM variables
4) Add to add_json_files_for.py  (THIS NEEDS TO BE PUT INTO MONGODB)
5) in frontend explorer.html, add source info to sources_json. 

